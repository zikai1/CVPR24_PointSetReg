<!DOCTYPE html
	PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">

<head>
	<title>Laplacian2Mesh: Laplacian-Based Mesh Understanding</title>
	<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">


	<!-- Meta tags for Zotero grab citation -->
	<meta name="citation_title" content="Laplacian2Mesh: Laplacian-Based Mesh Understanding">
	<meta name="citation_author" content="Qiujie Dong">
	<meta name="citation_author" content="Zixiong Wang">
	<meta name="citation_author" content="Manyi Li">
	<meta name="citation_author" content="Junjie Gao">
	<meta name="citation_author" content="Shuangmin Chen">
	<meta name="citation_author" content="Zhenyu Shu">
	<meta name="citation_author" content="Shiqing Xin">
	<meta name="citation_author" content="Changhe Tu">
    <meta name="citation_author" content="Wenping Wang">
	<meta name="citation_publication_date" content="2023">
	<meta name="citation_conference_title" content="IEEE Transactions on Visualization and Computer Graphics">
	<meta name="citation_pdf_url" content="https://doi.org/10.1109/TVCG.2023.3259044">

	<meta name="robots" content="index,follow">
	<meta name="description"
		content="Geometric deep learning has sparked a rising interest in computer graphics to perform shape understanding tasks,
		such as shape classification and semantic segmentation. When the input is a polygonal surface,
		one has to suffer from the irregular mesh structure. Motivated by the geometric spectral theory,
		we introduce Laplacian2Mesh, a novel and flexible convolutional neural network (CNN) framework for
		coping with irregular triangle meshes (vertices may have any valence).
		By mapping the input mesh surface to the multi-dimensional Laplacian-Beltrami space,
		Laplacian2Mesh enables one to perform shape analysis tasks directly using the mature CNNs,
		without the need to deal with the irregular connectivity of the mesh structure.
		We further define a mesh pooling operation such that the receptive field of the network can be expanded
		while retaining the original vertex set as well as the connections between them.
		Besides, we introduce a channel-wise self-attention block to learn the individual importance of feature ingredients.
		Laplacian2Mesh not only decouples the geometry from the irregular connectivity of the mesh structure
		but also better captures the global features that are central to shape classification and segmentation.
		Extensive tests on various datasets demonstrate the effectiveness and efficiency of Laplacian2Mesh,
		particularly in terms of the capability of being vulnerable to noise to fulfill various learning tasks.
		">
    <link rel="icon" type="image/png" href="/author/icon.jpg">

	<!-- Fonts and stuff -->
	<link href='http://fonts.googleapis.com/css?family=Open+Sans:400italic,700italic,800italic,400,700,800'
		rel='stylesheet' type='text/css'>
	<link rel="stylesheet" type="text/css" href="../../css/project.css" media="screen" />
	<link rel="stylesheet" type="text/css" media="screen" href="../../css/iconize.css" />
	<script src="js/google-code-prettify/prettify.js"></script>
</head>

<body>
	<div id="content">
		<div id="content-inner">
			<div class="section logos" style="text-align:center">
				<a href="https://www.en.sdu.edu.cn/" target="_blank" rel="noopener"><IMG src="../Assets/logos/logo_SDU.png" height="66" border="0"></a></td>
                <a href="https://en.qust.edu.cn/" target="_blank" rel="noopener"><IMG src="../Assets/logos/logo_QUST.png" height="66" border="0"></a></td>
                <a href="https://www.nbt.edu.cn/" target="_blank" rel="noopener"><IMG src="../Assets/logos/logo_NBT.png" height="66" border="0"></a></td>
                <a href="https://www.tamu.edu/" target="_blank" rel="noopener"><IMG src="../Assets/logos/logo_ATM.png" height="66" border="0"></a></td>
			</div>

			<div class="section head">

				<h1>Laplacian2Mesh: Laplacian-Based Mesh Understanding</h1>

				<div class="authors">
					<a href="https://qiujiedong.github.io/" itemprop="url" rel="noopener">Qiujie Dong</a><sup> 1</sup>&#160;&#160;
                    <a href="https://bearprin.com/" target="_blank" rel="noopener">Zixiong Wang</a><sup> 1</sup>&#160;&#160;
                    <a href="https://manyili12345.github.io/" target="_blank" rel="noopener">Manyi Li</a><sup> 1</sup>&#160;&#160;
                    <a href="https://scholar.google.com/citations?user=CTDs13EAAAAJ&hl" target="_blank" rel="noopener">Junjie Gao</a><sup> 1</sup>&#160;&#160;
                    <a href="https://ieeexplore.ieee.org/author/37088955375" target="_blank" rel="noopener">Shuangmin Chen</a><sup> 2</sup>&#160;&#160;
                    <a href="https://ieeexplore.ieee.org/author/37086874041" target="_blank" rel="noopener">Zhenyu Shu</a><sup> 3</sup>&#160;&#160;
                    <br>
                    <a href="http://irc.cs.sdu.edu.cn/~shiqing/index.html" target="_blank" rel="noopener">Shiqing Xin</a><sup> 1</sup>&#160;&#160;
                    <a href="http://irc.cs.sdu.edu.cn/~chtu/index.html" target="_blank" rel="noopener">Changhe Tu</a><sup> 1</sup>&#160;&#160;
                    <a href="https://engineering.tamu.edu/cse/profiles/Wang-Wenping.html" target="_blank" rel="noopener">Wenping Wang</a><sup> 4</sup>&#160;&#160;
				</div>

				<div class="affiliations">
					<sup>1</sup><a href="https://www.en.sdu.edu.cn/" target="_blank" rel="noopener">Shandong University</a>&#160;&#160;
					<sup>2</sup><a href="https://en.qust.edu.cn/" target="_blank" rel="noopener">Qingdao University of Science and Technology</a>&#160;&#160;
                    <br>
					<sup>3</sup><a href="https://www.nbt.edu.cn/" target="_blank" rel="noopener">Ningbo Institute of Technology, Zhejiang University</a>&#160;&#160;
                    <sup>4</sup><a href="https://www.tamu.edu/" target="_blank" rel="noopener">Texas A&M University</a>&#160;&#160;
				</div>
				<div class="venue"> IEEE Transactions on Visualization and Computer Graphics</div>
			</div>
			<div class="section downloads" style="text-align:center">
				<ul style="padding-left: 0">
					<li class="grid">
						<div class="griditem">
							<a href="https://ieeexplore.ieee.org/document/10076837" itemprop="url" rel="noopener"><img src="../Assets/images/TVCG.png"></a><br/>
							<a href="https://ieeexplore.ieee.org/document/10076837" itemprop="url" rel="noopener">Paper</a>
						</div>
					</li>
					<li class="grid">
						<div class="griditem">
							<a href="https://arxiv.org/abs/2202.00307" itemprop="url" rel="noopener"><img src="../Assets/images/arXiv.png"></a><br/>
							<a href="https://arxiv.org/abs/2202.00307" itemprop="url" rel="noopener">arXiv</a>
						</div>
					</li>
					<li class="grid">
						<div class="griditem">
							<a href="https://github.com/QiujieDong/Laplacian2Mesh" itemprop="url" rel="noopener"><img src="../Assets/images/github.png"></a><br/>
							<a href="https://github.com/QiujieDong/Laplacian2Mesh" itemprop="url" rel="noopener">Code</a>

						</div>
					</li>
				</ul>
			</div>


			<div class="section abstract">
				<h2>Abstract</h2><br>
				<div class="row" style="margin-bottom:5px">
					<div class="col" style="text-align:center">
						<img class="thumbnail" src="figs/spatial_transformations.png" style="width:85%; margin-bottom:20px">
					</div>

				</div>
				<p style="text-align:justify;">
					Geometric deep learning has sparked a rising interest in computer graphics to perform shape understanding tasks,
					such as shape classification and semantic segmentation. When the input is a polygonal surface,
					one has to suffer from the irregular mesh structure. Motivated by the geometric spectral theory,
					we introduce Laplacian2Mesh, a novel and flexible convolutional neural network (CNN) framework for
					coping with irregular triangle meshes (vertices may have any valence).
					By mapping the input mesh surface to the multi-dimensional Laplacian-Beltrami space,
					Laplacian2Mesh enables one to perform shape analysis tasks directly using the mature CNNs,
					without the need to deal with the irregular connectivity of the mesh structure.
					We further define a mesh pooling operation such that the receptive field of the network can be expanded
					while retaining the original vertex set as well as the connections between them.
					Besides, we introduce a channel-wise self-attention block to learn the individual importance of feature ingredients.
					Laplacian2Mesh not only decouples the geometry from the irregular connectivity of the mesh structure
					but also better captures the global features that are central to shape classification and segmentation.
					Extensive tests on various datasets demonstrate the effectiveness and efficiency of Laplacian2Mesh,
					particularly in terms of the capability of being vulnerable to noise to fulfill various learning tasks.
				</p>
			</div>

			<div class="section abstract">
				<h2>Introduction</h2><br>

				<p style="text-align:justify;">
					In this paper, we propose Laplacian2Mesh, inheriting the spirit of those spectral approaches,
					to make it possible to conduct learning tasks in the spectral domain when the input is a polygonal mesh.
					Note that the main technique of spectral approaches is to encode the overall shape by a subset of the
					eigenvectors decomposed from the Laplacian matrix of the input mesh.
					Two reasons account for why we advocate using the new representation in deep learning.
					First, as the low-frequency signals, given by those eigenvectors with small eigenvalues,
					encode the overall shape, they are more semantically important than high-frequency signals for most understanding tasks.
					It is easy for one to separate low-frequency signals from high-frequency signals in spectral approaches by setting a simple parameter k.
					Second, the Laplacian-based spectral transform can decouple shape variations from the tedious triangulation,
					avoiding tangling with tedious and irregular triangulations.
					Even if the input mesh contains a limited number of defects (e.g., non-manifold), the representation still works.
				</p>

				<div class="row" style="margin-bottom:5px">
					<div class="col" style="text-align:center">
						<img class="thumbnail" src="figs/pipeline.png" style="width:85%; margin-bottom:20px">
						<p>Pipeline of Laplacian2Mesh.</p>
					</div>
				</div>
				<p style="text-align:justify;">
					Our network pipeline for coping with the mesh classification and segmentation tasks. Given a 3D mesh as the input,
					we precompute the extrinsic and intrinsic geometric features and project them into the spectral domain w.r.t.
					three different resolutions. Inspired by the U-Net architecture,
					we propose to use the SE-ResNet blocks with small-sized convolution kernels to fuse the nearby-frequency features,
					and the Laplacian pooling/unpooling to fuse the spectral features of different resolutions.
					For the segmentation task, we re-scale (with the yellow block) and concatenate the features together to be processed
					by the segmentation block.
				</p>

				<div class="row" style="margin-bottom:5px">
					<div class="col" style="text-align:center">
						<img class="thumbnail" src="figs/pooling_unpooling.png" style="width:85%; margin-bottom:20px">
						<p>Pooling and Unpooling of Laplacian2Mesh.</p>
					</div>
				</div>
				<p style="text-align:justify;">
					The Laplacian pooling and unpooling operations transform the spectral-based features between different resolutions,
					where the pooling operation proceeds from a finer level to a coarser level while the unpooling operation does the opposite.
				</p>
			</div>

			<br>

			<div class="section abstract">
				<h2>Results</h2><br>

				<div class="row" style="margin-bottom:5px">
					<div class="col" style="text-align:center">
						<img class="thumbnail" src="figs/coseg_seg.png" style="width:95%; margin-bottom:20px">
						<p>
							Gallery of segmentation results for the COSEG dataset.
							From left to right, they are Tele-aliens, Chairs, and Vases.
						</p>
					</div>

					<div class="col" style="text-align:center">
						<img class="thumbnail" src="figs/humanbody_seg.png" style="width:80%; margin-bottom:20px">
						<p>
							We test the dataset of Human Body, and visualize the segmentation result for every model.
						</p>
					</div>
				</div>
			</div>

			<br>

			<div class="section abstract">
				<h2>Strengths</h2><br>
				<p style="text-align:justify;">
					Laplacian2Mesh combines the geometric spectral theory with deep learning,
					which overcomes the challenges of dealing with the irregular connectivity of meshes,
					and is a promising direction to understand 3D shapes in a tessellation independent manner.
					Our network inherits some merits of spectral analysis approaches.
					First, it can encode the shape features in various levels (from local to global) and naturally has a noise-resistance ability.
					Second, it is independent of mesh resolution/tesselation and can handle non-watertight, non-manifold, and incomplete triangle-meshes.
				</p>
				<div class="row" style="margin-bottom:5px">
					<div class="col" style="text-align:center">
						<img class="thumbnail" src="figs/anti-noise.png" style="width:95%; margin-bottom:20px">
						<p>
							The qualitative results of testing the noise-resistance.
							As noise levels rise, segmentation outputs of DiffusionNet diverge significantly from the ground-truth,
							while ours is more in line with it. Numbers are levels of Gaussian noise added.
							<br>
							(a) DiffusionNet-hks; (b) DiffusionNet-xyz; (c) Laplacian2Mesh; (d) Laplacian2Mesh (point cloud); (e) Ground-Truth.
						</p>
					</div>

					<div class="col" style="text-align:center">
						<img class="thumbnail" src="figs/un-manifold.png" style="width:95%; margin-bottom:20px">
						<p>
							Our Laplacian2Mesh is able to perform segmentation on the nonwatertight
							and non-manifold data.
							(a) and (b) are non-watertight vases and chairs,
							respectively; (c) has a non-manifold vertex, and (d) has a non-manifold edge.
						</p>
					</div>

					<div class="col" style="text-align:center">
						<img class="thumbnail" src="figs/incomplete_models.png" style="width:70%; margin-bottom:20px">
						<p>
							The results on incomplete models. The red dashed boxes on the mesh indicate the deleted parts.
							The green dashed boxes highlight the inaccurate segmentation boundaries.
						</p>
					</div>

				</div>
			</div>

			<div class="section list">
				<h2>Citation</h2>
				<div class="section bibtex">
					<pre>
@ARTICLE{Dong2023Laplacian2Mesh,
author={Dong, Qiujie and Wang, Zixiong and Li, Manyi and Gao, Junjie and Chen, Shuangmin and Shu, Zhenyu and Xin, Shiqing and Tu, Changhe and Wang, Wenping},
title={Laplacian2Mesh: Laplacian-Based Mesh Understanding},
journal={IEEE Transactions on Visualization and Computer Graphics},
year={2023},
pages={1-13},
doi={10.1109/TVCG.2023.3259044}
}					</pre>
				</div>
			</div>

			<div class="section">
				<hr class="smooth">
				This page is maintained by <a href="https://qiujiedong.github.io/" itemprop="url" rel="noopener">Qiujie Dong</a>.
<!--				Latest updated on-->
<!--				<script type="text/javascript">-->
<!--					var m = document.lastModified;-->
<!--					var p = m.length - 9;-->
<!--					document.write(m.substring(p, 0) + ".");-->
<!--            	</script>-->
			</div>
		</div>
	</div>
</body>
</html>